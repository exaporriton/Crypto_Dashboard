{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4b7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance import Client, ThreadedWebsocketManager, ThreadedDepthCacheManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from binance import Client, ThreadedWebsocketManager, ThreadedDepthCacheManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd27b05",
   "metadata": {},
   "source": [
    "# Run Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb153478",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r  bruno_api_key\n",
    "%store -r bruno_secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e90467b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/vf981v4x5tz8b5szmpt19_xm0000gp/T/ipykernel_25350/317025203.py:54: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['price_buckets'] = df['price_buckets'].str.replace(\"'\", \"\").str.replace(\"[\",\"\").str.replace(\"(\",\"\").str.replace(\")\",\"\").str.replace(\"]\",\"\").str.replace(\",\", \" -\")\n"
     ]
    }
   ],
   "source": [
    "# Binance API keys\n",
    "api_key = bruno_api_key\n",
    "secret_key = bruno_secret_key\n",
    "# Initialize Binance client\n",
    "client = Client(api_key, secret_key)\n",
    "\n",
    "# List of top_50 currencies to fetch data for\n",
    "top_50 = ['BTCUSDT', 'ETHUSDT','BNBUSDT','XRPUSDT','BUSDUSDT','ADAUSDT',\n",
    "          'DOGEUSDT','MATICUSDT','SOLUSDT','DOTUSDT','SHIBUSDT','LTCUSDT',\n",
    "          'TRXUSDT','AVAXUSDT','UNIUSDT','ATOMUSDT','LINKUSDT','ETCUSDT','XMRUSDT',\n",
    "          'BCHUSDT','HBARUSDT','XLMUSDT','APTUSDT','FILUSDT','LDOUSDT','NEARUSDT','APEUSDT',\n",
    "          'ALGOUSDT','VETUSDT','QNTUSDT','ICPUSDT','GRTUSDT','MANAUSDT','FTMUSDT','EOSUSDT',\n",
    "          'AAVEUSDT','SANDUSDT','EGLDUSDT','FLOWUSDT','THETAUSDT','AXSUSDT','XTZUSDT','LUNCUSDT',\n",
    "          'CHZUSDT','MINAUSDT','IMXUSDT','FXSUSDT','ZECUSDT','CAKEUSDT','MKRUSDT']\n",
    "\n",
    "# Get historical klines data for top_50 from 2022 until yesterday\n",
    "interval = Client.KLINE_INTERVAL_1DAY\n",
    "start_date = datetime.datetime(2022, 1, 1)\n",
    "end_date = datetime.datetime.today() - datetime.timedelta(days=1)\n",
    "end_date_str = end_date.strftime('%d %b %Y')\n",
    "historical_data = {}\n",
    "for symbol in top_50:\n",
    "    klines = client.get_historical_klines(symbol, interval, start_date.strftime('%d %b %Y'), '16 Jul 2023')\n",
    "    df = pd.DataFrame(klines, columns=['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time',\n",
    "                                           'quote_asset_volume', 'number_of_trades', 'tb_base_volume',\n",
    "                                           'tb_quote_volume', 'ignore'])\n",
    "    df['symbol'] = symbol\n",
    "    historical_data[symbol] = df\n",
    "#historical[i] = client.get_historical_klines(i, Client.KLINE_INTERVAL_1DAY, '1 Jan 2022', yesterday)\n",
    "\n",
    "# Concatenate historical data into a single dataframe\n",
    "df = pd.concat(historical_data.values(), ignore_index=True)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')\n",
    "\n",
    "#convert string columns into numbers \n",
    "numeric_columns = ['open', 'high', 'low', 'close','volume','quote_asset_volume','tb_base_volume','tb_quote_volume']\n",
    "df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# day of week column and day of month\n",
    "df['day_of_week'] = df['close_time'].dt.dayofweek\n",
    "df['day_of_month'] = df['close_time'].dt.day\n",
    "\n",
    "# Pct change column\n",
    "df['price_pct_change'] = df.groupby('symbol')['close'].pct_change().round(3)\n",
    "\n",
    "# Create column named 'price_buckets'\n",
    "df['price_buckets'] = df.groupby('symbol')['close'].transform(lambda x: pd.cut(x, 8))\n",
    "# Convert price buckets to string\n",
    "df['price_buckets'] = df['price_buckets'].astype(str)\n",
    "# Remove characters and replace the comma\n",
    "df['price_buckets'] = df['price_buckets'].str.replace(\"'\", \"\").str.replace(\"[\",\"\").str.replace(\"(\",\"\").str.replace(\")\",\"\").str.replace(\"]\",\"\").str.replace(\",\", \" -\")\n",
    "\n",
    "#Save historical data to file\n",
    "df.to_csv('historical_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c564a",
   "metadata": {},
   "source": [
    "# Schedule Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec5b2049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/vf981v4x5tz8b5szmpt19_xm0000gp/T/ipykernel_25350/4212496520.py:84: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['price_buckets'] = df['price_buckets'].str.replace(\"'\", \"\").str.replace(\"[\",\"\").str.replace(\"(\",\"\").str.replace(\")\",\"\").str.replace(\"]\",\"\").str.replace(\",\", \" -\")\n"
     ]
    }
   ],
   "source": [
    "from binance import Client, ThreadedWebsocketManager, ThreadedDepthCacheManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from binance import Client, ThreadedWebsocketManager, ThreadedDepthCacheManager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "historical_data_file = 'historical_data.csv'\n",
    "# Binance API keys\n",
    "api_key = bruno_api_key\n",
    "secret_key = bruno_secret_key\n",
    "# Initialize Binance client\n",
    "client = Client(api_key, secret_key)\n",
    "\n",
    "# List of top_50 currencies to fetch data for\n",
    "top_50 = ['BTCUSDT', 'ETHUSDT','BNBUSDT','XRPUSDT','BUSDUSDT','ADAUSDT',\n",
    "          'DOGEUSDT','MATICUSDT','SOLUSDT','DOTUSDT','SHIBUSDT','LTCUSDT',\n",
    "          'TRXUSDT','AVAXUSDT','UNIUSDT','ATOMUSDT','LINKUSDT','ETCUSDT','XMRUSDT',\n",
    "          'BCHUSDT','HBARUSDT','XLMUSDT','APTUSDT','FILUSDT','LDOUSDT','NEARUSDT','APEUSDT',\n",
    "          'ALGOUSDT','VETUSDT','QNTUSDT','ICPUSDT','GRTUSDT','MANAUSDT','FTMUSDT','EOSUSDT',\n",
    "          'AAVEUSDT','SANDUSDT','EGLDUSDT','FLOWUSDT','THETAUSDT','AXSUSDT','XTZUSDT','LUNCUSDT',\n",
    "          'CHZUSDT','MINAUSDT','IMXUSDT','FXSUSDT','ZECUSDT','CAKEUSDT','MKRUSDT']\n",
    "\n",
    "#load historical data\n",
    "historical_data = pd.read_csv(historical_data_file, parse_dates=['close_time'])\n",
    "last_date = historical_data['close_time'].max().date()\n",
    "\n",
    "# Start fetching new data\n",
    "fetch_start_date = last_date + datetime.timedelta(days=1)\n",
    "\n",
    "# Calculate the date to end fetching new data\n",
    "fetch_end_date = datetime.datetime.today().date() - datetime.timedelta(days=1)\n",
    "\n",
    "# setting up interval for fetching\n",
    "interval = Client.KLINE_INTERVAL_1DAY\n",
    "# Fetch historical data from Binance API for missing period\n",
    "if fetch_start_date <= fetch_end_date:\n",
    "    new_data = {}\n",
    "    for symbol in top_50:\n",
    "        klines = client.get_historical_klines(symbol, interval, fetch_start_date.strftime('%d %b %Y'),\n",
    "                                              fetch_end_date.strftime('%d %b %Y'))\n",
    "        df = pd.DataFrame(klines, columns=['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time',\n",
    "                                           'quote_asset_volume', 'number_of_trades', 'tb_base_volume',\n",
    "                                           'tb_quote_volume', 'ignore'])\n",
    "        df['symbol'] = symbol\n",
    "        new_data[symbol] = df\n",
    "\n",
    "# Concatenate the values of new_data to a df\n",
    "df = pd.concat(new_data.values(), ignore_index=True)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')\n",
    "\n",
    "#convert string columns into numbers \n",
    "numeric_columns = ['open', 'high', 'low', 'close','volume','quote_asset_volume','tb_base_volume','tb_quote_volume']\n",
    "df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# day of week column and day of month\n",
    "df['day_of_week'] = df['close_time'].dt.dayofweek\n",
    "df['day_of_month'] = df['close_time'].dt.day\n",
    "\n",
    "# Append new data to historical data\n",
    "# Changing the order due to the fact that we want to not have any NA values for price_pct change\n",
    "# Combine the old and new data\n",
    "combined_df = pd.concat([historical_data, df], ignore_index=True)\n",
    "\n",
    "# Pct change column\n",
    "combined_df['price_pct_change'] = combined_df.groupby('symbol')['close'].pct_change().round(3)\n",
    "df['price_pct_change'] = combined_df['price_pct_change']\n",
    "\n",
    "# Calculate the bin edges based on the 'close' prices in the combined data\n",
    "bin_edges = pd.cut(combined_df['close'], bins=8).cat.categories\n",
    "\n",
    "# Apply the calculated bin edges to the new data\n",
    "df['price_buckets'] = pd.cut(df['close'], bins=bin_edges)\n",
    "\n",
    "# Convert the 'price_buckets' column to string and remove unwanted characters\n",
    "df['price_buckets'] = df['price_buckets'].astype(str)\n",
    "df['price_buckets'] = df['price_buckets'].str.replace(\"'\", \"\").str.replace(\"[\",\"\").str.replace(\"(\",\"\").str.replace(\")\",\"\").str.replace(\"]\",\"\").str.replace(\",\", \" -\")\n",
    "\n",
    "# add the new rows to the existing csv file\n",
    "# Append new data to historical data\n",
    "final_df = pd.concat([historical_data, df], ignore_index=True)\n",
    "# Save historical data to file\n",
    "final_df.to_csv(historical_data_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
